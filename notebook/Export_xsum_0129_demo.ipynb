{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import PegasusTokenizer\n",
    "from transformers import PegasusForConditionalGeneration\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model_name=\"google/pegasus-xsum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_pegasus_model = PegasusForConditionalGeneration.from_pretrained(ori_model_name)\n",
    "ori_tokenizer = PegasusTokenizer.from_pretrained(ori_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_encoder(model, args, exported_model_path):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = torch.onnx._export(model,\n",
    "                           args,\n",
    "                           exported_model_path,\n",
    "                           export_params=True,\n",
    "                           opset_version=12,\n",
    "                           input_names=['input_ids'],\n",
    "                           output_names=['hidden_states'],\n",
    "                           dynamic_axes={\n",
    "                               'input_ids': {0:'batch', 1: 'sequence'},\n",
    "                               'hidden_states': {0:'batch', 1: 'sequence'},\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderWithLMHead(torch.nn.Module):\n",
    "    def __init__(self, decoder, lm_head, final_logits_bias):\n",
    "        super().__init__()\n",
    "        self.decoder = decoder\n",
    "        self.lm_head = lm_head\n",
    "        self.final_logits_bias = final_logits_bias\n",
    "        \n",
    "    def forward(self, input_ids, encoder_hidden_states):\n",
    "        outputs = self.decoder(input_ids=input_ids,\n",
    "                               attention_mask=None,\n",
    "                               encoder_hidden_states=encoder_hidden_states)\n",
    "        logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        log_softmaxed = F.log_softmax(next_token_logits, 1)\n",
    "        topk = torch.topk(log_softmaxed, 5, largest=True)\n",
    "        return topk.values, topk.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_decoder(model, decoder_inputs, encoded, model_path):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = torch.onnx.export(model,\n",
    "                  (decoder_inputs, encoded),\n",
    "                  output_decoder_path,\n",
    "                  export_params=True,\n",
    "                  opset_version=12,\n",
    "                  input_names=['input_ids', 'encoder_hidden_states'],\n",
    "                  output_names=['log_softmax', 'indices'],\n",
    "                  dynamic_axes={\n",
    "                          'input_ids': {0:'batch', 1: 'sequence'},\n",
    "                          'encoder_hidden_states': {0:'batch', 1: 'sequence_encoder_length'},\n",
    "                          'log_softmax': {0:'batch'},\n",
    "                          'indices': {0:'batch'},\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_encoder_path = \"./onnx_output/encoder_xsum_0129.onnx\"\n",
    "output_decoder_path = \"./onnx_output/decoder_lm_xsum_0129.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_text = \"\"\"\n",
    "I have been going over my folder.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_encoder_and_decoder(tokenizer, model, export_text, output_encoder_path, output_decoder_path):\n",
    "    export_input = tokenizer(export_text, return_tensors='pt')\n",
    "    export_encoder(model.model.encoder, export_input['input_ids'], output_encoder_path)\n",
    "    decoder_lm_head = DecoderWithLMHead(model.model.decoder, model.lm_head, model.final_logits_bias)\n",
    "    export_decoder(decoder_lm_head, export_input['input_ids'], model.model.encoder(input_ids=export_input['input_ids']).last_hidden_state,output_decoder_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_encoder_and_decoder(ori_tokenizer, ori_pegasus_model, export_text, output_encoder_path, output_decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pegasus_venv",
   "language": "python",
   "name": "pegasus_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
